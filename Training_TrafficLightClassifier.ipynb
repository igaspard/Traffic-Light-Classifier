{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "from scipy import misc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('trafficlight_images/*.jpg')\n",
    "\n",
    "for image in images:\n",
    "    img = cv2.imread(image)\n",
    "    resizeimg = cv2.resize(img, (100, 200), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(image.split('.')[0] + '_resize.jpg', resizeimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaspards/miniconda3/envs/py27_TF1.3/lib/python2.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Num of pictures to train: ', 300, 'Resolution: ', (200, 100, 3))\n"
     ]
    }
   ],
   "source": [
    "# IMAGE_PATH should be the path to the planesnet folder\n",
    "IMAGE_PATH = 'TrafficLight_Resize'\n",
    "file_paths = glob.glob(IMAGE_PATH + '/*resize.jpg')\n",
    "\n",
    "# Load the images\n",
    "images = [misc.imread(path) for path in file_paths]\n",
    "\n",
    "print('Num of pictures to train: ', len(images), 'Resolution: ', images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 200, 100, 3)\n",
      "[200 100   3]\n"
     ]
    }
   ],
   "source": [
    "images = np.asarray(images)\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "# Get image size\n",
    "image_size = np.asarray([images.shape[1], images.shape[2], images.shape[3]])\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "images = images / 255\n",
    "\n",
    "# Read the labels from the filenames\n",
    "n_images = images.shape[0]\n",
    "labels = np.zeros(n_images)\n",
    "for i in range(n_images):\n",
    "    #filename = path.basename(file_paths[i])[0]\n",
    "    filename = file_paths[i].split('/')[-1]\n",
    "    labels[i] = int(filename[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and training sets\n",
    "TRAIN_TEST_SPLIT = 0.8\n",
    "\n",
    "# Split at the given index\n",
    "split_index = int(TRAIN_TEST_SPLIT * n_images)\n",
    "shuffled_indices = np.random.permutation(n_images)\n",
    "train_indices = shuffled_indices[0:split_index]\n",
    "test_indices = shuffled_indices[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the images and the labels\n",
    "x_train = images[train_indices, :, :]\n",
    "y_train = labels[train_indices]\n",
    "x_test = images[test_indices, :, :]\n",
    "y_test = labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## MODEL CREATION ##\n",
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of convolutional filters to use\n",
    "filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = 2\n",
    "# convolution kernel size\n",
    "kernel_size = 3\n",
    "\n",
    "feature_layers = [\n",
    "    Conv2D(filters, kernel_size,\n",
    "           padding='valid',\n",
    "           input_shape=image_size),\n",
    "    Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=pool_size),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "]\n",
    "\n",
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 98, 32)       896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 198, 98, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 196, 96, 32)       9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 196, 96, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 98, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 98, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 150528)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               19267712  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 19,278,243\n",
      "Trainable params: 19,278,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "240/240 [==============================] - 76s - loss: 0.0024 - acc: 1.0000     \n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 73s - loss: 0.0014 - acc: 1.0000     \n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 74s - loss: 0.0012 - acc: 1.0000     \n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 75s - loss: 6.1201e-04 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 75s - loss: 3.4216e-04 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 71s - loss: 5.7698e-04 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 73s - loss: 3.0159e-04 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 73s - loss: 3.0497e-04 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 72s - loss: 2.8489e-04 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 73s - loss: 2.2314e-04 - acc: 1.0000     \n"
     ]
    }
   ],
   "source": [
    "# create complete model\n",
    "model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "## MODEL TRAINING ##\n",
    "# Training Hyperparamters\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adadelta',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_one_hot, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL EVALUATION ##\n",
    "# Make a prediction on the test set\n",
    "test_predictions = model.predict(x_test)\n",
    "test_predictions = np.round(test_predictions)\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Report the accuracy\n",
    "accuracy = accuracy_score(y_one_hot_test, test_predictions)\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 98, 32)       896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 198, 98, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 196, 96, 32)       9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 196, 96, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 98, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 98, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 150528)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               19267712  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 19,278,243\n",
      "Trainable params: 19,278,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[1. 0. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Try inference couple samples\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')\n",
    "model.summary()\n",
    "\n",
    "test1_img = cv2.imread('trafficlight_images/1_image10.jpg')\n",
    "test1_img = cv2.resize(test1_img, (100, 200), interpolation=cv2.INTER_CUBIC)\n",
    "test1_img = np.asarray(test1_img) / 255\n",
    "\n",
    "test2_img = cv2.imread('trafficlight_images/0_image104.jpg')\n",
    "test2_img = cv2.resize(test2_img, (100, 200), interpolation=cv2.INTER_CUBIC)\n",
    "test2_img = np.asarray(test2_img) / 255\n",
    "\n",
    "test3_img = cv2.imread('trafficlight_images/2_image44.jpg')\n",
    "test3_img = cv2.resize(test3_img, (100, 200), interpolation=cv2.INTER_CUBIC)\n",
    "test3_img = np.asarray(test3_img) / 255\n",
    "\n",
    "test = np.array([test1_img, test2_img, test3_img])\n",
    "\n",
    "test_pred = model.predict(test)\n",
    "test_pred = np.round(test_pred)\n",
    "\n",
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "result = label_binarizer.inverse_transform(test_pred)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
