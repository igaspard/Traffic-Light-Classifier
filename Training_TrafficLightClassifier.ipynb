{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('trafficlight_images/*.jpg')\n",
    "\n",
    "for image in images:\n",
    "    img = cv2.imread(image)\n",
    "    resizeimg = cv2.resize(img, (120, 256), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(image.split('.')[0] + '_resize.jpg', resizeimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaspards/miniconda3/envs/py27_TF1.3/lib/python2.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Num of pictures to train: ', 540, 'Resolution: ', (256, 120, 3))\n"
     ]
    }
   ],
   "source": [
    "# IMAGE_PATH should be the path to the planesnet folder\n",
    "IMAGE_PATH = 'TrafficLight_Small'\n",
    "file_paths = glob.glob(IMAGE_PATH + '/*resize.jpg')\n",
    "\n",
    "# Load the images\n",
    "images = [misc.imread(path) for path in file_paths]\n",
    "\n",
    "print('Num of pictures to train: ', len(images), 'Resolution: ', images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 256, 120, 3)\n",
      "[256 120   3]\n"
     ]
    }
   ],
   "source": [
    "images = np.asarray(images)\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "# Get image size\n",
    "image_size = np.asarray([images.shape[1], images.shape[2], images.shape[3]])\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "images = images / 255\n",
    "\n",
    "# Read the labels from the filenames\n",
    "n_images = images.shape[0]\n",
    "labels = np.zeros(n_images)\n",
    "for i in range(n_images):\n",
    "    #filename = path.basename(file_paths[i])[0]\n",
    "    filename = file_paths[i].split('/')[-1]\n",
    "    labels[i] = int(filename[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into test and training sets\n",
    "TRAIN_TEST_SPLIT = 0.9\n",
    "\n",
    "# Split at the given index\n",
    "split_index = int(TRAIN_TEST_SPLIT * n_images)\n",
    "shuffled_indices = np.random.permutation(n_images)\n",
    "train_indices = shuffled_indices[0:split_index]\n",
    "test_indices = shuffled_indices[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the images and the labels\n",
    "x_train = images[train_indices, :, :]\n",
    "y_train = labels[train_indices]\n",
    "x_test = images[test_indices, :, :]\n",
    "y_test = labels[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## MODEL CREATION ##\n",
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparamaters\n",
    "N_LAYERS = 4\n",
    "\n",
    "def cnn(size, n_layers):\n",
    "    # INPUTS\n",
    "    # size     - size of the input images\n",
    "    # n_layers - number of layers\n",
    "    # OUTPUTS\n",
    "    # model    - compiled CNN\n",
    "\n",
    "    # Define model hyperparamters\n",
    "    MIN_NEURONS = 20\n",
    "    MAX_NEURONS = 120\n",
    "    KERNEL = (3, 3)\n",
    "\n",
    "    # Determine the # of neurons in each convolutional layer\n",
    "    steps = np.floor(MAX_NEURONS / (n_layers + 1))\n",
    "    nuerons = np.arange(MIN_NEURONS, MAX_NEURONS, steps)\n",
    "    nuerons = nuerons.astype(np.int32)\n",
    "\n",
    "    # Define a model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add convolutional layers\n",
    "    for i in range(0, n_layers):\n",
    "        if i == 0:\n",
    "            shape = (size[0], size[1], size[2])\n",
    "            model.add(Conv2D(nuerons[i], KERNEL, input_shape=shape))\n",
    "        else:\n",
    "            model.add(Conv2D(nuerons[i], KERNEL))\n",
    "\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    # Add max pooling layer with dropout\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(MAX_NEURONS))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Print a summary of the model\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/gaspards/miniconda3/envs/py27_TF1.3/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/gaspards/miniconda3/envs/py27_TF1.3/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 254, 118, 20)      560       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 254, 118, 20)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 252, 116, 44)      7964      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 252, 116, 44)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 250, 114, 68)      26996     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 250, 114, 68)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 248, 112, 92)      56396     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 248, 112, 92)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 124, 56, 92)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 638848)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               76661880  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 363       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 76,754,159\n",
      "Trainable params: 76,754,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = cnn(size=image_size, n_layers=N_LAYERS)\n",
    "\n",
    "\n",
    "## MODEL TRAINING ##\n",
    "# Training Hyperparamters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "# Early stopping callback\n",
    "PATIENCE = 10\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=PATIENCE, verbose=0, mode='auto')\n",
    "\n",
    "# TensorBoard callback\n",
    "#LOG_DIRECTORY_ROOT = 'logdir'\n",
    "#now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "#log_dir = \"{}/run-{}/\".format(LOG_DIRECTORY_ROOT, now)\n",
    "#tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, write_images=True)\n",
    "\n",
    "# Place the callbacks in a list\n",
    "#callbacks = [early_stopping, tensorboard]\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_one_hot, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=callbacks, verbose=0)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL EVALUATION ##\n",
    "# Make a prediction on the test set\n",
    "test_predictions = model.predict(x_test)\n",
    "test_predictions = np.round(test_predictions)\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the accuracy\n",
    "accuracy = accuracy_score(y_one_hot_test, test_predictions)\n",
    "print(\"Accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try inference couple samples\n",
    "#test1_img = misc.imread('trafficlight_images/1_image306_resize.jpg')\n",
    "test1_img = cv2.imread('trafficlight_images/1_image327_resize.jpg')\n",
    "test1_img = np.asarray(test1_img) / 255\n",
    "\n",
    "test2_img = cv2.imread('trafficlight_images/0_image296_resize.jpg')\n",
    "test2_img = np.asarray(test2_img) / 255\n",
    "\n",
    "test3_img = cv2.imread('trafficlight_images/2_image293_resize.jpg')\n",
    "test3_img = np.asarray(test3_img) / 255\n",
    "\n",
    "test = np.array([test1_img, test2_img, test3_img])\n",
    "\n",
    "test_pred = model.predict(test)\n",
    "test_pred = np.round(test_pred)\n",
    "\n",
    "#from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "result = label_binarizer.inverse_transform(test_pred)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
